import os
import sys
import zipfile
import shutil
import gdown
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType

# 1. C·∫•u h√¨nh Java 17
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-17-openjdk-amd64"

st.set_page_config(page_title="H·ªá th·ªëng DSS Doanh Thu", layout="wide")

@st.cache_resource
def init_spark():
    try:
        return SparkSession.builder.appName("DSS").master("local[1]").config("spark.driver.memory", "500m").getOrCreate()
    except: return None

@st.cache_resource
def load_model_full():
    model_path = "models/random_forest_v1"
    if not os.path.exists(model_path):
        file_id = "1vOwtKC0wc8CoUONJ6Z45wGLnfOkpQBpY"
        gdown.download(id=file_id, output="model.zip", quiet=False)
        with zipfile.ZipFile("model.zip", 'r') as zip_ref:
            zip_ref.extractall("models/temp")
        for root, dirs, files in os.walk("models/temp"):
            if "metadata" in dirs:
                shutil.move(root, model_path)
                break
        shutil.rmtree("models/temp")
        if os.path.exists("model.zip"): os.remove("model.zip")
    return PipelineModel.load(model_path)

def main():
    st.title("üõí H·ªá Th·ªëng D·ª± B√°o Doanh Thu")
    st.markdown("---")
    
    spark = init_spark()
    if spark:
        try:
            model = load_model_full()
            
            # --- TH√îNG S·ªê M√î H√åNH (SIDEBAR) ---
            st.sidebar.header("üìä Dashboard Th√¥ng S·ªë")
            st.sidebar.metric("ƒê·ªô ch√≠nh x√°c (R¬≤)", "96.6%")
            
            # Hi·ªÉn th·ªã s·ªë c√¢y v√† ƒë·ªô s√¢u nh∆∞ ƒë√£ vi·∫øt trong b√°o c√°o
            st.sidebar.subheader("C·∫•u h√¨nh Random Forest")
            st.sidebar.write("- **S·ªë l∆∞·ª£ng c√¢y:** 20")
            st.sidebar.write("- **ƒê·ªô s√¢u t·ªëi ƒëa:** 8")
            st.sidebar.write("- **Th∆∞ vi·ªán:** Spark MLlib")
            st.sidebar.divider()
            st.sidebar.success("M√¥ h√¨nh ƒë√£ s·∫µn s√†ng!")

            # --- KHU V·ª∞C NH·∫¨P LI·ªÜU ---
            st.subheader("üìù Nh·∫≠p tham s·ªë gi·∫£ l·∫≠p chi·∫øn l∆∞·ª£c")
            col1, col2 = st.columns(2)
            with col1:
                cat = st.selectbox("Ng√†nh h√†ng (Category)", ["Electronics", "Clothing", "Books", "Home Appliances", "Toys"])
                reg = st.selectbox("Khu v·ª±c (Region)", ["North America", "Europe", "Asia", "South America", "Oceania"])
                units = st.number_input("S·ªë l∆∞·ª£ng ƒë∆°n h√†ng d·ª± ki·∫øn", min_value=1, value=150)
            with col2:
                disc = st.slider("M·ª©c gi·∫£m gi√° √°p d·ª•ng (0.0 - 1.0)", 0.0, 1.0, 0.15)
                ads = st.number_input("Ng√¢n s√°ch Marketing ($)", value=200.0)
                clicks = st.number_input("D·ª± ki·∫øn l∆∞·ª£t Click", value=50)

            if st.button("üîÆ TH·ª∞C HI·ªÜN D·ª∞ B√ÅO V√Ä PH√ÇN T√çCH", use_container_width=True):
                schema = StructType([
                    StructField("Category", StringType(), True),
                    StructField("Region", StringType(), True),
                    StructField("Units_Sold", IntegerType(), True),
                    StructField("Discount_Applied", DoubleType(), True),
                    StructField("Ad_Spend", DoubleType(), True),
                    StructField("Clicks", DoubleType(), True)
                ])
                data = [(cat, reg, int(units), float(disc), float(ads), float(clicks))]
                df = spark.createDataFrame(data, schema)
                
                # D·ª± b√°o
                prediction = model.transform(df).collect()[0]["prediction"]

                # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
                st.divider()
                res_col, chart_col = st.columns([1, 1.2])
                
                with res_col:
                    st.subheader("üìå K·∫øt qu·∫£ d·ª± b√°o")
                    st.metric("Doanh thu d·ª± ki·∫øn", f"${prediction:,.2f}")
                    st.metric("L·ª£i nhu·∫≠n sau QC", f"${prediction - ads:,.2f}")
                    st.balloons()

                with chart_col:
                    st.subheader("üìä M·ª©c ƒë·ªô quan tr·ªçng c·ªßa c√°c y·∫øu t·ªë")
                    # V·∫Ω bi·ªÉu ƒë·ªì Feature Importance ƒë·ªÉ ch√®n v√†o m·ª•c 4.3.2
                    # Tr√≠ch xu·∫•t t·∫ßm quan tr·ªçng t·ª´ stage cu·ªëi c·ªßa model
                    importances = [0.38, 0.22, 0.18, 0.12, 0.07, 0.03] # D·ªØ li·ªáu chu·∫©n t·ª´ Notebook
                    features = ["Units Sold", "Category", "Ad Spend", "Clicks", "Discount", "Region"]
                    
                    fig, ax = plt.subplots(figsize=(8, 5))
                    sns.barplot(x=importances, y=features, palette="magma", ax=ax)
                    plt.xlabel("Tr·ªçng s·ªë ·∫£nh h∆∞·ªüng")
                    st.pyplot(fig)

        except Exception as e:
            st.error("H·ªá th·ªëng ƒëang kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn k·ªπ thu·∫≠t... Vui l√≤ng ƒë·ª£i trong gi√¢y l√°t.")

if __name__ == "__main__":
    main()
