import os
import sys

# Thi·∫øt l·∫≠p Java 17 cho Streamlit Cloud
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-17-openjdk-amd64"

import streamlit as st
from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType
import gdown

# C·∫•u h√¨nh giao di·ªán
st.set_page_config(page_title="D·ª± B√°o Doanh Thu Th∆∞∆°ng M·∫°i ƒêi·ªán T·ª≠", layout="wide")

@st.cache_resource
def init_spark():
    try:
        spark = SparkSession.builder \
            .appName("RevenuePredictor") \
            .master("local[1]") \
            .config("spark.driver.bindAddress", "127.0.0.1") \
            .getOrCreate()
        return spark
    except Exception as e:
        return None

@st.cache_resource
def download_model():
    model_path = "models/random_forest_v1"
    if os.path.exists(model_path):
        return model_path
    folder_id = "1ESwDvLGSlxRXFgnNqW-LPC9ETZbN6tkQ"
    os.makedirs("models", exist_ok=True)
    url = f"https://drive.google.com/drive/folders/{folder_id}"
    try:
        gdown.download_folder(url, output="models/", quiet=False, use_cookies=False)
        return model_path
    except:
        return None

def main():
    st.title("üõí H·ªá Th·ªëng D·ª± B√°o Doanh Thu Th∆∞∆°ng M·∫°i ƒêi·ªán T·ª≠")
    st.info("M√¥ h√¨nh s·ª≠ d·ª•ng: Random Forest (R¬≤ ~ 96.6%)")
    
    spark = init_spark()
    model_path = download_model()
    
    if not spark or not model_path:
        st.warning("ƒêang kh·ªüi t·∫°o h·ªá th·ªëng...")
        return

    try:
        model = PipelineModel.load(model_path)
        st.success("‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")
        
        # B·ªë tr√≠ c√°c √¥ nh·∫≠p li·ªáu
        col1, col2 = st.columns(2)
        
        with col1:
            category = st.selectbox("Lo·∫°i S·∫£n Ph·∫©m (Category)", ["Electronics", "Home & Kitchen", "Clothing", "Books", "Toys"])
            region = st.selectbox("Khu V·ª±c (Region)", ["North", "South", "East", "West"])
            units_sold = st.number_input("S·ªë L∆∞·ª£ng B√°n (Units Sold)", min_value=1, value=100)
            discount_val = st.slider("M·ª©c Gi·∫£m Gi√° (Discount %)", 0.0, 1.0, 0.1) # Th∆∞·ªùng l√† t·ª´ 0 ƒë·∫øn 1 trong d·ªØ li·ªáu m·∫´u

        with col2:
            ad_spend = st.number_input("Chi Ph√≠ Qu·∫£ng C√°o ($)", min_value=0.0, value=200.0)
            clicks = st.number_input("S·ªë L∆∞·ª£t Click (Clicks)", min_value=0, value=50) # TH√äM BI·∫æN B·ªä THI·∫æU
            # Hai bi·∫øn d∆∞·ªõi ƒë√¢y c√≥ th·ªÉ kh√¥ng d√πng trong model nh∆∞ng d√πng ƒë·ªÉ t√≠nh l·ª£i nhu·∫≠n
            reviews = st.slider("ƒê√°nh Gi√° (Reviews - tham kh·∫£o)", 1.0, 5.0, 4.0)
            shipping = st.number_input("Ph√≠ V·∫≠n Chuy·ªÉn ($)", value=5.0)

        if st.button("üîÆ B·∫Øt ƒê·∫ßu D·ª± B√°o", use_container_width=True):
            # SCHEMA CHU·∫®N: Ph·∫£i ch·ª©a c√°c c·ªôt m√† m√¥ h√¨nh mong ƒë·ª£i
            # D·ª±a tr√™n notebook: Units_Sold, Discount_Applied, Ad_Spend, Clicks, Category, Region
            schema = StructType([
                StructField("Category", StringType(), True),
                StructField("Region", StringType(), True),
                StructField("Units_Sold", IntegerType(), True),
                StructField("Discount_Applied", DoubleType(), True), # T√™n c·ªôt trong m√¥ h√¨nh l√† Discount_Applied
                StructField("Ad_Spend", DoubleType(), True),
                StructField("Clicks", DoubleType(), True), # C·ªôt Clicks
                # Th√™m c√°c c·ªôt ph·ª• ƒë·ªÉ tr√°nh l·ªói schema n·∫øu m√¥ h√¨nh c√≥ tham chi·∫øu
                StructField("Customer_Reviews", DoubleType(), True),
                StructField("Shipping_Cost", DoubleType(), True)
            ])
            
            input_data = [(
                str(category), 
                str(region), 
                int(units_sold), 
                float(discount_val), 
                float(ad_spend), 
                float(clicks),
                float(reviews),
                float(shipping)
            )]
            
            df = spark.createDataFrame(input_data, schema)
            
            # Th·ª±c hi·ªán transform (d·ª± b√°o)
            prediction_df = model.transform(df)
            result = prediction_df.collect()[0]["prediction"]
            
            st.divider()
            st.balloons()
            st.header(f"üìä Doanh Thu D·ª± B√°o: ${result:,.2f}")
            
            # T√≠nh to√°n l·ª£i nhu·∫≠n
            profit = result - (ad_spend + (shipping * units_sold))
            st.subheader(f"üí∞ L·ª£i Nhu·∫≠n ∆Ø·ªõc T√≠nh: ${profit:,.2f}")

    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói: {e}")

if __name__ == "__main__":
    main()
