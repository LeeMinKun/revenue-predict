import os
import sys

# 1. THI·∫æT L·∫¨P JAVA 17 (C·ª±c k·ª≥ quan tr·ªçng cho Spark tr√™n Colab)
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-17-openjdk-amd64"
os.environ["PATH"] = os.environ["JAVA_HOME"] + "/bin:" + os.environ["PATH"]

import streamlit as st
import pandas as pd
from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType
import gdown

# 2. KH·ªûI T·∫†O SPARK
@st.cache_resource
def init_spark():
    try:
        spark = SparkSession.builder \
            .appName("RevenuePredictor") \
            .master("local[*]") \
            .config("spark.driver.bindAddress", "127.0.0.1") \
            .getOrCreate()
        return spark
    except Exception as e:
        st.error(f"L·ªói kh·ªüi ƒë·ªông Spark: {e}")
        return None

# 3. T·∫¢I M√î H√åNH
@st.cache_resource
def download_model():
    model_path = "models/random_forest_v1"
    if os.path.exists(model_path):
        return model_path
    
    folder_id = "1ESwDvLGSlxRXFgnNqW-LPC9ETZbN6tkQ"
    os.makedirs("models", exist_ok=True)
    url = f"https://drive.google.com/drive/folders/{folder_id}"
    
    try:
        gdown.download_folder(url, output="models/", quiet=False, use_cookies=False)
        return model_path
    except Exception as e:
        st.error(f"L·ªói t·∫£i model: {e}")
        return None

# 4. GIAO DI·ªÜN CH√çNH
def main():
    st.set_page_config(page_title="D·ª± B√°o Doanh Thu", layout="wide")
    st.title("üõí H·ªá Th·ªëng D·ª± B√°o Doanh Thu Th∆∞∆°ng M·∫°i ƒêi·ªán T·ª≠")
    
    spark = init_spark()
    model_path = download_model()
    
    if spark and model_path:
        try:
            model = PipelineModel.load(model_path)
            st.success("‚úÖ M√¥ h√¨nh Random Forest ƒë√£ s·∫µn s√†ng!")
            
            # Form nh·∫≠p li·ªáu
            with st.form(key="prediction_form"):
                col1, col2 = st.columns(2)
                
                with col1:
                    category = st.selectbox("Lo·∫°i S·∫£n Ph·∫©m", ["Electronics", "Home & Kitchen", "Clothing", "Books", "Toys"])
                    units_sold = st.number_input("S·ªë L∆∞·ª£ng B√°n", min_value=1, value=50)
                    discount = st.slider("M·ª©c Gi·∫£m Gi√° (%)", 0.0, 50.0, 10.0)
                
                with col2:
                    ad_spend = st.number_input("Chi Ph√≠ Qu·∫£ng C√°o ($)", value=500.0)
                    reviews = st.slider("ƒê√°nh Gi√° Kh√°ch H√†ng", 1.0, 5.0, 4.0)
                    shipping = st.number_input("Chi Ph√≠ V·∫≠n Chuy·ªÉn ($)", value=5.0)
                
                # N√∫t Submit (B·∫ÆT BU·ªòC PH·∫¢I TH·ª§T L·ªÄ ·ªû ƒê√ÇY)
                submitted = st.form_submit_button("üîÆ D·ª± B√°o Doanh Thu")
                
                if submitted:
                    schema = StructType([
                        StructField("Category", StringType(), True),
                        StructField("Units_Sold", IntegerType(), True),
                        StructField("Discount", DoubleType(), True),
                        StructField("Ad_Spend", DoubleType(), True),
                        StructField("Customer_Reviews", DoubleType(), True),
                        StructField("Shipping_Cost", DoubleType(), True)
                    ])
                    input_data = [(category, int(units_sold), float(discount), float(ad_spend), float(reviews), float(shipping))]
                    df = spark.createDataFrame(input_data, schema)
                    
                    prediction = model.transform(df).collect()[0]["prediction"]
                    
                    st.divider()
                    st.header(f"üìä K·∫øt qu·∫£ d·ª± b√°o: ${prediction:,.2f}")

        except Exception as e:
            st.error(f"L·ªói load m√¥ h√¨nh: {e}")

if __name__ == "__main__":
    main()
