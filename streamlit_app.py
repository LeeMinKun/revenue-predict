import os
import sys
import zipfile
import shutil
import gdown
import streamlit as st
from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType

# C·∫•u h√¨nh Java 17 cho Streamlit Cloud
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-17-openjdk-amd64"

st.set_page_config(page_title="D·ª± B√°o Doanh Thu", layout="wide")

@st.cache_resource
def init_spark():
    try:
        spark = SparkSession.builder \
            .appName("RevenuePredictor") \
            .master("local[1]") \
            .config("spark.driver.memory", "512m") \
            .config("spark.ui.showConsoleProgress", "false") \
            .getOrCreate()
        return spark
    except Exception as e:
        return None

@st.cache_resource
def download_and_prepare_model():
    # Th∆∞ m·ª•c ƒë√≠ch m√† Spark s·∫Ω load
    final_model_path = "models/random_forest_v1"
    zip_path = "model.zip"
    extract_path = "models/temp_extract"
    
    if os.path.exists(final_model_path):
        return final_model_path
    
    file_id = "1vOwtKC0wc8CoUONJ6Z45wGLnfOkpQBpY"
    
    try:
        # 1. T·∫£i file d√πng ID (tr√°nh l·ªói permission URL)
        gdown.download(id=file_id, output=zip_path, quiet=False)
        
        # 2. Gi·∫£i n√©n v√†o th∆∞ m·ª•c t·∫°m
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_path)
        
        # 3. KI·ªÇM TRA C·∫§U TR√öC TH∆Ø M·ª§C (X·ª≠ l√Ω l·ªói Path Not Found)
        # T√¨m xem th∆∞ m·ª•c 'metadata' n·∫±m ·ªü ƒë√¢u
        actual_path = extract_path
        for root, dirs, files in os.walk(extract_path):
            if "metadata" in dirs:
                actual_path = root
                break
        
        # 4. Di chuy·ªÉn v·ªÅ ƒë√∫ng v·ªã tr√≠ chu·∫©n
        os.makedirs("models", exist_ok=True)
        if os.path.exists(final_model_path):
            shutil.rmtree(final_model_path)
        shutil.move(actual_path, final_model_path)
        
        # D·ªçn d·∫πp
        if os.path.exists(zip_path): os.remove(zip_path)
        if os.path.exists(extract_path): shutil.rmtree(extract_path)
            
        return final_model_path
    except Exception as e:
        st.error(f"L·ªói chu·∫©n b·ªã m√¥ h√¨nh: {e}")
        return None

def main():
    st.title("üõí H·ªá Th·ªëng D·ª± B√°o Doanh Thu")
    
    spark = init_spark()
    # S·ª≠ d·ª•ng h√†m chu·∫©n h√≥a ƒë∆∞·ªùng d·∫´n m·ªõi
    model_path = download_prepare_model() if 'download_prepare_model' in locals() else download_and_prepare_model()
    
    if spark and model_path:
        try:
            # Spark load PipelineModel t·ª´ th∆∞ m·ª•c c√≥ ch·ª©a folder 'metadata'
            model = PipelineModel.load(model_path)
            st.success("‚úÖ M√¥ h√¨nh ƒë√£ n·∫°p th√†nh c√¥ng!")
            
            # Giao di·ªán nh·∫≠p li·ªáu
            with st.container():
                col1, col2 = st.columns(2)
                with col1:
                    category = st.selectbox("Lo·∫°i S·∫£n Ph·∫©m", ["Electronics", "Home & Kitchen", "Clothing", "Books", "Toys"])
                    region = st.selectbox("Khu V·ª±c", ["North", "South", "East", "West"])
                    units = st.number_input("S·ªë L∆∞·ª£ng B√°n", min_value=1, value=100)
                    disc_app = st.selectbox("√Åp d·ª•ng gi·∫£m gi√°?", ["Yes", "No"])
                with col2:
                    disc_val = st.slider("M·ª©c Gi·∫£m Gi√° (0.0-1.0)", 0.0, 1.0, 0.1)
                    ads = st.number_input("Qu·∫£ng C√°o ($)", value=200.0)
                    clicks = st.number_input("S·ªë L∆∞·ª£t Click", value=50)
                    ship = st.number_input("Ph√≠ V·∫≠n Chuy·ªÉn ($)", value=5.0)

            if st.button("üîÆ D·ª± B√°o Ngay", use_container_width=True):
                schema = StructType([
                    StructField("Category", StringType(), True),
                    StructField("Region", StringType(), True),
                    StructField("Discount_Applied", StringType(), True),
                    StructField("Units_Sold", IntegerType(), True),
                    StructField("Discount", DoubleType(), True),
                    StructField("Ad_Spend", DoubleType(), True),
                    StructField("Clicks", DoubleType(), True),
                    StructField("Customer_Reviews", DoubleType(), True),
                    StructField("Shipping_Cost", DoubleType(), True)
                ])
                
                # Customer_Reviews m·∫∑c ƒë·ªãnh 4.0 v√¨ model y√™u c·∫ßu 9 c·ªôt
                data = [(category, region, disc_app, int(units), float(disc_val), float(ads), float(clicks), 4.0, float(ship))]
                df = spark.createDataFrame(data, schema)
                pred = model.transform(df).collect()[0]["prediction"]
                
                st.divider()
                st.header(f"üìä D·ª± b√°o: ${pred:,.2f}")
                
        except Exception as e:
            st.error(f"L·ªói load m√¥ h√¨nh: {e}")

if __name__ == "__main__":
    main()
