import os
import sys

# 1. C·∫•u h√¨nh Java 17
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-17-openjdk-amd64"
os.environ["PATH"] = os.environ["JAVA_HOME"] + "/bin:" + os.environ["PATH"]

import streamlit as st
import pandas as pd
from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType
import gdown

# C·∫•u h√¨nh trang
st.set_page_config(page_title="D·ª± B√°o Doanh Thu", layout="wide")

@st.cache_resource
def init_spark():
    try:
        spark = SparkSession.builder \
            .appName("RevenuePredictor") \
            .master("local[*]") \
            .config("spark.driver.bindAddress", "127.0.0.1") \
            .getOrCreate()
        return spark
    except Exception as e:
        return None

@st.cache_resource
def download_model():
    model_path = "models/random_forest_v1"
    if os.path.exists(model_path):
        return model_path
    folder_id = "1ESwDvLGSlxRXFgnNqW-LPC9ETZbN6tkQ"
    os.makedirs("models", exist_ok=True)
    url = f"https://drive.google.com/drive/folders/{folder_id}"
    try:
        gdown.download_folder(url, output="models/", quiet=False, use_cookies=False)
        return model_path
    except:
        return None

def main():
    st.title("üõí H·ªá Th·ªëng D·ª± B√°o Doanh Thu Th∆∞∆°ng M·∫°i ƒêi·ªán T·ª≠")
    
    spark = init_spark()
    model_path = download_model()
    
    if not spark or not model_path:
        st.error("ƒêang kh·ªüi t·∫°o h·ªá th·ªëng ho·∫∑c t·∫£i m√¥ h√¨nh...")
        return

    try:
        model = PipelineModel.load(model_path)
        st.success("‚úÖ M√¥ h√¨nh Random Forest ƒë√£ s·∫µn s√†ng!")
        
        st.subheader("üìù Nh·∫≠p Th√¥ng Tin S·∫£n Ph·∫©m")
        col1, col2 = st.columns(2)
        
        with col1:
            category = st.selectbox("Lo·∫°i S·∫£n Ph·∫©m", ["Electronics", "Home & Kitchen", "Clothing", "Books", "Toys"])
            region = st.selectbox("Khu V·ª±c (Region)", ["North", "South", "East", "West"])
            units_sold = st.number_input("S·ªë L∆∞·ª£ng B√°n", min_value=1, value=50)
            
        with col2:
            discount = st.slider("M·ª©c Gi·∫£m Gi√° (%)", 0.0, 50.0, 10.0)
            ad_spend = st.number_input("Chi Ph√≠ Qu·∫£ng C√°o ($)", min_value=0.0, value=500.0)
            reviews = st.slider("ƒê√°nh Gi√° Kh√°ch H√†ng", 1.0, 5.0, 4.0)
            shipping = st.number_input("Chi Ph√≠ V·∫≠n Chuy·ªÉn ($)", min_value=0.0, value=5.0)

        # S·ª≠ d·ª•ng n√∫t b·∫•m b√¨nh th∆∞·ªùng, kh√¥ng d√πng Form
        if st.button("üîÆ D·ª± B√°o Doanh Thu", use_container_width=True):
            # T·∫°o Schema d·ª±a tr√™n notebook Nhom1_KPDLL2.ipynb
            schema = StructType([
                StructField("Category", StringType(), True),
                StructField("Region", StringType(), True),
                StructField("Units_Sold", IntegerType(), True),
                StructField("Discount", DoubleType(), True),
                StructField("Ad_Spend", DoubleType(), True),
                StructField("Customer_Reviews", DoubleType(), True),
                StructField("Shipping_Cost", DoubleType(), True)
            ])
            
            input_data = [(str(category), str(region), int(units_sold), float(discount), float(ad_spend), float(reviews), float(shipping))]
            df = spark.createDataFrame(input_data, schema)
            
            # D·ª± b√°o
            prediction_df = model.transform(df)
            result = prediction_df.collect()[0]["prediction"]
            
            st.divider()
            st.balloons()
            st.header(f"üìä Doanh thu d·ª± b√°o: ${result:,.2f}")
            
            # T√≠nh l·ª£i nhu·∫≠n ∆∞·ªõc t√≠nh
            profit = result - (ad_spend + (shipping * units_sold))
            st.subheader(f"üí∞ L·ª£i nhu·∫≠n ∆∞·ªõc t√≠nh: ${profit:,.2f}")

    except Exception as e:
        st.error(f"L·ªói: {e}")

if __name__ == "__main__":
    main()
